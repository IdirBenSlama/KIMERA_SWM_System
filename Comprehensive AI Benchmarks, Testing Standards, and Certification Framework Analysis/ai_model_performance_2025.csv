Model,GPQA Diamond (%),AIME Math (%),HumanEval Code (%),MMLU (%),Model Type,Release Date,Average Score
OpenAI o3,83.3,91.6,94.2,92.5,Closed,2025-04,90.39999999999999
Gemini 2.5 Pro,86.4,92.0,89.2,91.2,Closed,2025-05,89.7
OpenAI o4-mini,81.4,93.4,91.8,90.1,Closed,2025-04,89.17500000000001
GPT-4.5 Preview,82.1,88.9,93.1,91.8,Closed,2025-02,88.97500000000001
Grok 3 [Beta],84.6,93.3,87.1,89.8,Closed,2025-02,88.7
GPT-4o Latest,78.5,85.2,90.5,89.7,Closed,2025-03,85.975
OpenAI o3-mini,79.7,87.3,88.5,87.9,Closed,2025-04,85.85
Claude Opus 4,77.2,82.4,89.7,88.9,Closed,2025-05,84.55000000000001
Nemotron Ultra 253B,76.0,80.08,83.7,89.5,Open,2025-01,82.32
DeepSeek-R1,71.5,79.8,85.3,88.4,Open,2025-01,81.25
Claude 3.5 Sonnet,59.4,71.1,92.0,88.3,Closed,2024-10,77.7
Llama 4 Behemoth,73.7,65.2,81.2,87.2,Open,2025-03,76.825
Llama 4 Maverick,69.8,68.1,79.8,86.1,Open,2025-03,75.94999999999999
