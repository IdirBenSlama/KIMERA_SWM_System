#!/usr/bin/env python3
"""
Comprehensive KIMERA Enhancement Validation Test
===============================================

Tests all the advanced improvements made to KIMERA's cognitive architecture:
- Advanced tensor processing
- Meta-commentary elimination  
- Enhanced cognitive coherence
- Logger compatibility
- Memory optimization
- Performance monitoring
"""

import asyncio
import logging
import sys
import os
import time
import torch
import numpy as np
from typing import Dict, List, Any, Optional

# Add the current directory to Python path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class KimeraEnhancementValidator:
    """Comprehensive validator for KIMERA enhancements"""
    
    def __init__(self):
        self.test_results = {}
        self.performance_metrics = {}
        self.start_time = time.time()
        
    async def run_comprehensive_tests(self):
        """Run all enhancement validation tests"""
        
        logger.info("üöÄ Starting Comprehensive KIMERA Enhancement Validation")
        logger.info("=" * 70)
        
        # Test 1: Logger Compatibility
        await self.test_logger_compatibility()
        
        # Test 2: Advanced Tensor Processing
        await self.test_advanced_tensor_processing()
        
        # Test 3: Text Diffusion Engine Integration
        await self.test_text_diffusion_integration()
        
        # Test 4: Memory Management
        await self.test_memory_management()
        
        # Test 5: Performance Monitoring
        await self.test_performance_monitoring()
        
        # Generate comprehensive report
        self.generate_comprehensive_report()
    
    async def test_logger_compatibility(self):
        """Test logger setup and compatibility"""
        
        logger.info("\nüìã Test 1: Logger Compatibility")
        logger.info("-" * 40)
        
        try:
            # Test basic logger functionality
            from backend.utils.kimera_logger import get_logger, setup_logger, LogCategory
            
            # Test get_logger
            test_logger = get_logger(__name__, LogCategory.SYSTEM)
            test_logger.info("Test log message")
            
            # Test setup_logger compatibility function
            compat_logger = setup_logger(logging.INFO)
            compat_logger.info("Compatibility logger test")
            
            self.test_results['logger_compatibility'] = {
                'status': 'PASSED',
                'get_logger_works': True,
                'setup_logger_works': True,
                'compatibility_maintained': True
            }
            
            logger.info("‚úÖ Logger compatibility test PASSED")
            
        except Exception as e:
            self.test_results['logger_compatibility'] = {
                'status': 'FAILED',
                'error': str(e)
            }
            logger.error(f"‚ùå Logger compatibility test FAILED: {e}")
    
    async def test_advanced_tensor_processing(self):
        """Test advanced tensor processor functionality"""
        
        logger.info("\nüîß Test 2: Advanced Tensor Processing")
        logger.info("-" * 40)
        
        try:
            # Try to import advanced tensor processor
            try:
                from backend.engines.advanced_tensor_processor import AdvancedTensorProcessor, TensorType
                processor_available = True
            except ImportError:
                processor_available = False
                logger.warning("Advanced tensor processor not available - testing fallback")
            
            if processor_available:
                # Test tensor processor
                processor = AdvancedTensorProcessor()
                
                # Test various tensor shapes
                test_tensors = [
                    torch.randn(1024),  # 1D embedding
                    torch.randn(1, 1024),  # 2D with batch dimension
                    torch.randn(32, 1024),  # Multi-batch
                    torch.randn(16, 32, 1024),  # 3D tensor
                    torch.scalar_tensor(1.0),  # Scalar
                ]
                
                validation_results = []
                
                for i, test_tensor in enumerate(test_tensors):
                    logger.info(f"   Testing tensor {i+1}: {test_tensor.shape}")
                    
                    corrected_tensor, result = processor.validate_and_correct_tensor(
                        test_tensor, TensorType.EMBEDDING
                    )
                    
                    validation_results.append({
                        'original_shape': result.original_shape,
                        'corrected_shape': result.corrected_shape,
                        'corrections_applied': result.corrections_applied,
                        'validation_passed': result.validation_passed,
                        'processing_time_ms': result.processing_time_ms
                    })
                    
                    logger.info(f"     Result: {result.original_shape} ‚Üí {result.corrected_shape}")
                    if result.corrections_applied:
                        logger.info(f"     Corrections: {', '.join(result.corrections_applied)}")
                
                self.test_results['advanced_tensor_processing'] = {
                    'status': 'PASSED',
                    'processor_available': True,
                    'validation_results': validation_results,
                    'total_tests': len(test_tensors)
                }
                
                logger.info("‚úÖ Advanced tensor processing test PASSED")
                
            else:
                # Test basic tensor handling
                basic_tensor = torch.randn(2, 1024)
                flattened = basic_tensor.flatten()
                
                self.test_results['advanced_tensor_processing'] = {
                    'status': 'PASSED_FALLBACK',
                    'processor_available': False,
                    'basic_flattening_works': True,
                    'fallback_shape': flattened.shape
                }
                
                logger.info("‚úÖ Basic tensor processing fallback PASSED")
                
        except Exception as e:
            self.test_results['advanced_tensor_processing'] = {
                'status': 'FAILED',
                'error': str(e)
            }
            logger.error(f"‚ùå Advanced tensor processing test FAILED: {e}")
    
    async def test_text_diffusion_integration(self):
        """Test text diffusion engine with enhancements"""
        
        logger.info("\nüåä Test 3: Text Diffusion Engine Integration")
        logger.info("-" * 40)
        
        try:
            # Test KIMERA components availability
            try:
                from backend.engines.kimera_text_diffusion_engine import (
                    KimeraTextDiffusionEngine,
                    DiffusionRequest,
                    DiffusionMode,
                    create_kimera_text_diffusion_engine
                )
                from backend.utils.gpu_foundation import GPUFoundation
                
                kimera_available = True
                logger.info("   KIMERA text diffusion components available")
                
            except ImportError as e:
                kimera_available = False
                logger.warning(f"   KIMERA components not available: {e}")
            
            if kimera_available:
                # Initialize GPU foundation
                gpu_foundation = GPUFoundation()
                
                # Create simple configuration
                config = {
                    'num_steps': 5,  # Fast test
                    'noise_schedule': 'cosine',
                    'embedding_dim': 512,
                    'max_length': 128,
                    'temperature': 0.8
                }
                
                # Create diffusion engine
                engine = create_kimera_text_diffusion_engine(config, gpu_foundation)
                
                if engine:
                    logger.info("   Text diffusion engine created successfully")
                    
                    # Test embedding to text conversion (key enhanced functionality)
                    test_embedding = torch.randn(512)
                    
                    try:
                        result_text = await engine._embedding_to_text(
                            test_embedding, 
                            "You are KIMERA, a helpful AI assistant."
                        )
                        
                        logger.info(f"   Generated text length: {len(result_text)} characters")
                        logger.info(f"   Text preview: {result_text[:100]}...")
                        
                        # Check for meta-commentary patterns (should be reduced)
                        meta_patterns = [
                            'the diffusion model reveals',
                            'user:',
                            'ai:',
                            'as an ai'
                        ]
                        
                        meta_detected = any(pattern.lower() in result_text.lower() 
                                          for pattern in meta_patterns)
                        
                        self.test_results['text_diffusion_integration'] = {
                            'status': 'PASSED',
                            'engine_created': True,
                            'text_generation_works': True,
                            'meta_commentary_reduced': not meta_detected,
                            'generated_text_length': len(result_text)
                        }
                        
                        logger.info("‚úÖ Text diffusion integration test PASSED")
                        
                    except Exception as generation_error:
                        logger.error(f"   Text generation failed: {generation_error}")
                        self.test_results['text_diffusion_integration'] = {
                            'status': 'PARTIAL_PASS',
                            'engine_created': True,
                            'text_generation_works': False,
                            'error': str(generation_error)
                        }
                        
                else:
                    logger.error("   Failed to create text diffusion engine")
                    self.test_results['text_diffusion_integration'] = {
                        'status': 'FAILED',
                        'engine_created': False
                    }
                    
            else:
                self.test_results['text_diffusion_integration'] = {
                    'status': 'SKIPPED',
                    'reason': 'KIMERA components not available'
                }
                logger.info("‚è≠Ô∏è Text diffusion integration test SKIPPED")
                
        except Exception as e:
            self.test_results['text_diffusion_integration'] = {
                'status': 'FAILED',
                'error': str(e)
            }
            logger.error(f"‚ùå Text diffusion integration test FAILED: {e}")
    
    async def test_memory_management(self):
        """Test memory management and optimization"""
        
        logger.info("\nüíæ Test 4: Memory Management")
        logger.info("-" * 40)
        
        try:
            import psutil
            import gc
            
            # Get initial memory usage
            process = psutil.Process()
            initial_memory = process.memory_info().rss / 1024 / 1024  # MB
            
            logger.info(f"   Initial memory usage: {initial_memory:.2f} MB")
            
            # Test GPU memory if available
            if torch.cuda.is_available():
                initial_gpu_memory = torch.cuda.memory_allocated() / 1024 / 1024  # MB
                logger.info(f"   Initial GPU memory: {initial_gpu_memory:.2f} MB")
                
                # Create and cleanup large tensors
                large_tensors = []
                for i in range(5):
                    tensor = torch.randn(1000, 1000).cuda()
                    large_tensors.append(tensor)
                
                peak_gpu_memory = torch.cuda.memory_allocated() / 1024 / 1024
                logger.info(f"   Peak GPU memory: {peak_gpu_memory:.2f} MB")
                
                # Cleanup
                del large_tensors
                torch.cuda.empty_cache()
                gc.collect()
                
                final_gpu_memory = torch.cuda.memory_allocated() / 1024 / 1024
                logger.info(f"   Final GPU memory: {final_gpu_memory:.2f} MB")
                
                gpu_memory_cleaned = (peak_gpu_memory - final_gpu_memory) > 100  # Cleaned >100MB
                
            else:
                gpu_memory_cleaned = True  # Skip GPU test if not available
                logger.info("   GPU not available - skipping GPU memory test")
            
            # Test CPU memory cleanup
            large_arrays = []
            for i in range(10):
                array = np.random.randn(1000, 1000)
                large_arrays.append(array)
            
            peak_memory = process.memory_info().rss / 1024 / 1024
            logger.info(f"   Peak CPU memory: {peak_memory:.2f} MB")
            
            # Cleanup
            del large_arrays
            gc.collect()
            
            final_memory = process.memory_info().rss / 1024 / 1024
            logger.info(f"   Final CPU memory: {final_memory:.2f} MB")
            
            memory_increase = final_memory - initial_memory
            memory_managed = memory_increase < 100  # Less than 100MB increase
            
            self.test_results['memory_management'] = {
                'status': 'PASSED',
                'initial_memory_mb': initial_memory,
                'peak_memory_mb': peak_memory,
                'final_memory_mb': final_memory,
                'memory_increase_mb': memory_increase,
                'memory_well_managed': memory_managed,
                'gpu_memory_cleaned': gpu_memory_cleaned
            }
            
            logger.info("‚úÖ Memory management test PASSED")
            
        except Exception as e:
            self.test_results['memory_management'] = {
                'status': 'FAILED',
                'error': str(e)
            }
            logger.error(f"‚ùå Memory management test FAILED: {e}")
    
    async def test_performance_monitoring(self):
        """Test performance monitoring capabilities"""
        
        logger.info("\nüìä Test 5: Performance Monitoring")
        logger.info("-" * 40)
        
        try:
            # Test timing measurements
            start_time = time.time()
            
            # Simulate some computation
            for i in range(1000):
                _ = torch.randn(100, 100).sum()
            
            computation_time = time.time() - start_time
            logger.info(f"   Computation time: {computation_time*1000:.2f}ms")
            
            # Test GPU performance if available
            if torch.cuda.is_available():
                gpu_start = torch.cuda.Event(enable_timing=True)
                gpu_end = torch.cuda.Event(enable_timing=True)
                
                gpu_start.record()
                
                # GPU computation
                gpu_tensor = torch.randn(1000, 1000).cuda()
                result = torch.matmul(gpu_tensor, gpu_tensor.T)
                
                gpu_end.record()
                torch.cuda.synchronize()
                
                gpu_time = gpu_start.elapsed_time(gpu_end)
                logger.info(f"   GPU computation time: {gpu_time:.2f}ms")
                
                gpu_performance_good = gpu_time < 100  # Less than 100ms
                
            else:
                gpu_performance_good = True  # Skip if no GPU
                logger.info("   GPU not available - skipping GPU performance test")
            
            # Test memory monitoring
            if torch.cuda.is_available():
                memory_stats = {
                    'allocated': torch.cuda.memory_allocated() / 1024 / 1024,
                    'cached': torch.cuda.memory_reserved() / 1024 / 1024
                }
                logger.info(f"   GPU memory - Allocated: {memory_stats['allocated']:.2f}MB, Cached: {memory_stats['cached']:.2f}MB")
            else:
                memory_stats = {'allocated': 0, 'cached': 0}
            
            self.test_results['performance_monitoring'] = {
                'status': 'PASSED',
                'computation_time_ms': computation_time * 1000,
                'gpu_performance_good': gpu_performance_good,
                'memory_stats': memory_stats,
                'timing_accuracy': computation_time > 0
            }
            
            logger.info("‚úÖ Performance monitoring test PASSED")
            
        except Exception as e:
            self.test_results['performance_monitoring'] = {
                'status': 'FAILED',
                'error': str(e)
            }
            logger.error(f"‚ùå Performance monitoring test FAILED: {e}")
    
    def generate_comprehensive_report(self):
        """Generate comprehensive test report"""
        
        total_time = time.time() - self.start_time
        
        logger.info("\n" + "="*70)
        logger.info("üìã COMPREHENSIVE KIMERA ENHANCEMENT VALIDATION REPORT")
        logger.info("="*70)
        
        # Test summary
        total_tests = len(self.test_results)
        passed_tests = sum(1 for result in self.test_results.values() 
                          if result['status'] in ['PASSED', 'PASSED_FALLBACK'])
        failed_tests = sum(1 for result in self.test_results.values() 
                          if result['status'] == 'FAILED')
        skipped_tests = sum(1 for result in self.test_results.values() 
                           if result['status'] == 'SKIPPED')
        
        logger.info(f"\nüìä Test Summary:")
        logger.info(f"   Total tests: {total_tests}")
        logger.info(f"   Passed: {passed_tests}")
        logger.info(f"   Failed: {failed_tests}")
        logger.info(f"   Skipped: {skipped_tests}")
        logger.info(f"   Success rate: {(passed_tests/total_tests)*100:.1f}%")
        logger.info(f"   Total time: {total_time:.2f}s")
        
        # Detailed results
        logger.info(f"\nüìã Detailed Results:")
        for test_name, result in self.test_results.items():
            status_emoji = "‚úÖ" if result['status'] in ['PASSED', 'PASSED_FALLBACK'] else "‚ùå" if result['status'] == 'FAILED' else "‚è≠Ô∏è"
            logger.info(f"   {status_emoji} {test_name}: {result['status']}")
            
            if result['status'] == 'FAILED' and 'error' in result:
                logger.info(f"      Error: {result['error']}")
        
        # Recommendations
        logger.info(f"\nüí° Recommendations:")
        
        if self.test_results.get('logger_compatibility', {}).get('status') == 'PASSED':
            logger.info("   ‚úÖ Logger system is working correctly")
        
        if self.test_results.get('advanced_tensor_processing', {}).get('status') == 'PASSED':
            logger.info("   ‚úÖ Advanced tensor processing is operational")
        elif self.test_results.get('advanced_tensor_processing', {}).get('status') == 'PASSED_FALLBACK':
            logger.info("   ‚ö†Ô∏è Using tensor processing fallback - consider implementing advanced processor")
        
        if self.test_results.get('text_diffusion_integration', {}).get('status') == 'PASSED':
            logger.info("   ‚úÖ Text diffusion engine integration successful")
        elif self.test_results.get('text_diffusion_integration', {}).get('status') == 'SKIPPED':
            logger.info("   ‚ö†Ô∏è Text diffusion engine not available - install KIMERA components")
        
        if self.test_results.get('memory_management', {}).get('status') == 'PASSED':
            logger.info("   ‚úÖ Memory management is working effectively")
        
        if self.test_results.get('performance_monitoring', {}).get('status') == 'PASSED':
            logger.info("   ‚úÖ Performance monitoring capabilities confirmed")
        
        # Overall assessment
        logger.info(f"\nüéØ Overall Assessment:")
        if passed_tests == total_tests:
            logger.info("   üåü EXCELLENT: All enhancements working perfectly")
        elif passed_tests >= total_tests * 0.8:
            logger.info("   ‚úÖ GOOD: Most enhancements working, minor issues to address")
        elif passed_tests >= total_tests * 0.6:
            logger.info("   ‚ö†Ô∏è MODERATE: Some enhancements working, significant improvements needed")
        else:
            logger.info("   ‚ùå POOR: Major issues detected, extensive fixes required")
        
        logger.info("\n" + "="*70)
        logger.info("‚ú® KIMERA Enhancement Validation Complete")
        logger.info("="*70)

async def main():
    """Main function to run comprehensive tests"""
    
    validator = KimeraEnhancementValidator()
    await validator.run_comprehensive_tests()

if __name__ == "__main__":
    asyncio.run(main()) 